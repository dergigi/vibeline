# Ollama model configuration
# You can use different models for different tasks
OLLAMA_EXTRACT_MODEL=llama2
OLLAMA_SUMMARIZE_MODEL=llama2
OLLAMA_DEFAULT_MODEL=llama2

# Ollama connection configuration (optional)
# OLLAMA_HOST=http://localhost:11434

# Path configuration
VOICE_MEMOS_DIR=VoiceMemos

# Whisper model configuration
WHISPER_MODEL=base.en
