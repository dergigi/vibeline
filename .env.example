LLM_PROVIDER=ollama # openai

# Ollama model configuration
# You can use different models for different tasks
# For better performance, use tinyllama (smaller, faster)
# For better quality, use llama3 or any ollama model: https://ollama.com/search
OLLAMA_HOST=...

DEFAULT_MODEL=tinyllama

OPENAI_API_KEY=sk-...
OPENAI_BASE_URL=..

# Ollama connection configuration (optional)
# OLLAMA_HOST=http://localhost:11434

# Path configuration
VOICE_MEMOS_DIR=VoiceMemos
VOCABULARY_FILE=VOCABULARY.txt

# Whisper model configuration
WHISPER_MODEL=base.en

# Blossom uploads
BLOSSOM_SERVER=haven.sovereignengineering.io
NOSTR_SECRET_KEY=nsec... # or ncryptsec
